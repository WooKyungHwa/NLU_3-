{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "최지현_sts.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPOsASpz9UOA2VPiw2Zu5BL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "088ca6a973f64736b33ebe087c89241c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2b787aa8963f4cb999e6eb48a8f5c287",
              "IPY_MODEL_c9be71f8a15a48a796442a02f21a2da5",
              "IPY_MODEL_c953953d30604b6da64f42f1cba34927"
            ],
            "layout": "IPY_MODEL_511ce7e8491440e1b337fad379cb522d"
          }
        },
        "2b787aa8963f4cb999e6eb48a8f5c287": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb68f9059933431e9af56b2c32df0dd6",
            "placeholder": "​",
            "style": "IPY_MODEL_b139e372e12644b1ab9f6ee48b358611",
            "value": "100%"
          }
        },
        "c9be71f8a15a48a796442a02f21a2da5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0002c4b10a942d6a4b07ed16245041e",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e056e139480341ceaf390414fa632e3d",
            "value": 2
          }
        },
        "c953953d30604b6da64f42f1cba34927": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5edda9e5eb54d7aadd6db3b3fe5fa71",
            "placeholder": "​",
            "style": "IPY_MODEL_4dbaccef710d4a58aa9247ecfbee4817",
            "value": " 2/2 [00:00&lt;00:00, 60.42it/s]"
          }
        },
        "511ce7e8491440e1b337fad379cb522d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb68f9059933431e9af56b2c32df0dd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b139e372e12644b1ab9f6ee48b358611": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0002c4b10a942d6a4b07ed16245041e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e056e139480341ceaf390414fa632e3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e5edda9e5eb54d7aadd6db3b3fe5fa71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4dbaccef710d4a58aa9247ecfbee4817": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ttogle918/NLU_3-/blob/main/%EC%B5%9C%EC%A7%80%ED%98%84_sts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **NLU - 문장 유사도 계산 (STS)**\n",
        "\n"
      ],
      "metadata": {
        "id": "xMjisMbV8egY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 과제 목표\n",
        "  - 두 개의 한국어 문장을 입력받아 두 문장의 의미적 유사도를 출력\n",
        "  - regression task ( 0 <= target <= 5 ) **=> klue 결과값이 0~5이다! logit을 정규화할 필요!**\n",
        "    -  as a real value from 0 (no meaning overlap) to 5 (meaning equivalence)\n",
        "    - [klue](https://klue-benchmark.com/tasks/67/overview/description)\n",
        "- 학습 데이터 셋 ( 다운로드 가능 & 제공 예정 )\n",
        "  - KLUE-STS\n",
        "    - AIRBNB ( 리뷰 )\n",
        "    - policy ( 뉴스 )\n",
        "    - paraKOQC ( 스마트홈 쿼리 )\n",
        "- 과제 결과물\n",
        "  - 학습된 모델 ( 모델 자유 선택 ) ( train set만 사용해 학습 )\n",
        "  - 학습 방식 보고서\n",
        "    - 어떤 모델을 선택했나\n",
        "    - 어떻게 파라미터를 튜닝했나\n",
        "    - 어떤 훈련 과정을 거쳤는가\n",
        "  - dev set score ( F1 )\n",
        "  - 문장 유사도를 출력하는 API ( 프레임워크 자유 선택 )"
      ],
      "metadata": {
        "id": "8IxJAFOS83jQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- [graykode/ALBERT-Pytorch](https://github.com/graykode/ALBERT-Pytorch)\n",
        "- [huggingface](https://huggingface.co/docs/transformers/model_doc/albert)\n",
        "\n",
        "\n",
        "유사도 계산.. 순서는 상관없는 것 같다..\n",
        "\n",
        "albert가 sop(문장 순서 예측)을 통해 모델을 훈련하기 때문에 사용하려고 했는데, 유사도만 계산하는 것이기 때문에 albert를 사용할 때 장점이 크지는 않을 것 같다."
      ],
      "metadata": {
        "id": "WAU2Idm1iC9I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "해야할 부분 \n",
        "\n",
        "1. train data에서 train할 동안 검증할 validation 추출?\n",
        "2. 모델 logit 0~5 사이로 정규화\n",
        "3. 모델 클래스 작성!\n",
        "4. train 메소드 작성..\n",
        "5. ..."
      ],
      "metadata": {
        "id": "YWjZR_nXkZqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# gpu 연산이 가능하면 'cuda:0', 아니면 'cpu' 출력\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device, torch.cuda.device_count()"
      ],
      "metadata": {
        "id": "ayvjtv81TpLW",
        "outputId": "2411bfda-cc1c-41f7-b120-cb99853cb9f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(device(type='cuda', index=0), 1)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model load\n",
        "!pip install pytorch-transformers"
      ],
      "metadata": {
        "id": "ctFKX352qtdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install datasets"
      ],
      "metadata": {
        "id": "s4O435R1pSPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ev_s6Hh8h6KR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from tqdm import tqdm, tqdm_notebook"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForNextSentencePrediction, BertTokenizerFast, BertConfig\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from transformers.optimization import get_cosine_schedule_with_warmup\n",
        "from transformers import AdamW"
      ],
      "metadata": {
        "id": "fuuFJ9c_vaHu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- \"klue/roberta-large\"\n",
        "- \"klue/roberta-small\"\n",
        "- \"klue/roberta-base\"\n",
        "- \"klue/bert-base\"\n",
        "- [klue에 등록된 모델](https://huggingface.co/klue)\n",
        "- [한국어언어모델](https://littlefoxdiary.tistory.com/81)"
      ],
      "metadata": {
        "id": "xOVzxvVDV_4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://huggingface.co/kykim/albert-kor-base\n",
        "\n",
        "# tokenizer = BertTokenizerFast.from_pretrained(\"snunlp/KR-Medium\")"
      ],
      "metadata": {
        "id": "V7L5HN96pL8V"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KLUE 데이터셋\n",
        "\n",
        "[klue-sts-벤치마크-구조-보기](https://velog.io/@soyoun9798/KLUE-STS-%EB%B2%A4%EC%B9%98%EB%A7%88%ED%81%AC-%EA%B5%AC%EC%A1%B0-%EB%B3%B4%EA%B8%B0)\n"
      ],
      "metadata": {
        "id": "3l3wMury3Blb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset('klue', 'sts')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "088ca6a973f64736b33ebe087c89241c",
            "2b787aa8963f4cb999e6eb48a8f5c287",
            "c9be71f8a15a48a796442a02f21a2da5",
            "c953953d30604b6da64f42f1cba34927",
            "511ce7e8491440e1b337fad379cb522d",
            "bb68f9059933431e9af56b2c32df0dd6",
            "b139e372e12644b1ab9f6ee48b358611",
            "a0002c4b10a942d6a4b07ed16245041e",
            "e056e139480341ceaf390414fa632e3d",
            "e5edda9e5eb54d7aadd6db3b3fe5fa71",
            "4dbaccef710d4a58aa9247ecfbee4817"
          ]
        },
        "id": "hCQ-gQlZznhA",
        "outputId": "5706db59-650a-4854-f998-2aaacb2f8f68"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reusing dataset klue (/root/.cache/huggingface/datasets/klue/sts/1.0.0/e0fc3bc3de3eb03be2c92d72fd04a60ecc71903f821619cb28ca0e1e29e4233e)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "088ca6a973f64736b33ebe087c89241c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"type(dataset) : {type(dataset)}\")\n",
        "print(f\"key : {dataset.keys()}\")\n",
        "print(f\"type dataset[train] : {type(dataset['train'])}\")\n",
        "print(f\"dataset[train] : {dataset['train']} \\n\\n\")\n",
        "# labels : { 이진분류 : 1, 반올림 값 : 3.7, 실제 label 값 : 3.71422... }\n",
        "dataset['train'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9qplkC53DTD",
        "outputId": "67f910e1-5b60-4f6e-9656-a1a79ca35a46"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "type(dataset) : <class 'datasets.dataset_dict.DatasetDict'>\n",
            "key : dict_keys(['train', 'validation'])\n",
            "type dataset[train] : <class 'datasets.arrow_dataset.Dataset'>\n",
            "dataset[train] : Dataset({\n",
            "    features: ['guid', 'source', 'sentence1', 'sentence2', 'labels'],\n",
            "    num_rows: 11668\n",
            "}) \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'guid': 'klue-sts-v1_train_00000',\n",
              " 'labels': {'binary-label': 1, 'label': 3.7, 'real-label': 3.714285714285714},\n",
              " 'sentence1': '숙소 위치는 찾기 쉽고 일반적인 한국의 반지하 숙소입니다.',\n",
              " 'sentence2': '숙박시설의 위치는 쉽게 찾을 수 있고 한국의 대표적인 반지하 숙박시설입니다.',\n",
              " 'source': 'airbnb-rtt'}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 10개만 확인\n",
        "i = 0\n",
        "for d in dataset['train'] :\n",
        "  if i == 10 : break\n",
        "  print(d)\n",
        "  i += 1"
      ],
      "metadata": {
        "id": "pYSX9gRHdEM-",
        "outputId": "584ed91c-01c4-4c4f-dfff-43122097499e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'guid': 'klue-sts-v1_train_00000', 'source': 'airbnb-rtt', 'sentence1': '숙소 위치는 찾기 쉽고 일반적인 한국의 반지하 숙소입니다.', 'sentence2': '숙박시설의 위치는 쉽게 찾을 수 있고 한국의 대표적인 반지하 숙박시설입니다.', 'labels': {'label': 3.7, 'real-label': 3.714285714285714, 'binary-label': 1}}\n",
            "{'guid': 'klue-sts-v1_train_00001', 'source': 'policy-sampled', 'sentence1': '위반행위 조사 등을 거부·방해·기피한 자는 500만원 이하 과태료 부과 대상이다.', 'sentence2': '시민들 스스로 자발적인 예방 노력을\\xa0한 것은 아산 뿐만이 아니었다.', 'labels': {'label': 0.0, 'real-label': 0.0, 'binary-label': 0}}\n",
            "{'guid': 'klue-sts-v1_train_00002', 'source': 'paraKQC-sampled', 'sentence1': '회사가 보낸 메일은 이 지메일이 아니라 다른 지메일 계정으로 전달해줘.', 'sentence2': '사람들이 주로 네이버 메일을 쓰는 이유를 알려줘', 'labels': {'label': 0.3, 'real-label': 0.3333333333333333, 'binary-label': 0}}\n",
            "{'guid': 'klue-sts-v1_train_00003', 'source': 'policy-sampled', 'sentence1': '긴급 고용안정지원금은 지역고용대응 등 특별지원금, 지자체별 소상공인 지원사업, 취업성공패키지, 청년구직활동지원금, 긴급복지지원제도 지원금과는 중복 수급이 불가능하다.', 'sentence2': '고용보험이 1차 고용안전망이라면, 국민취업지원제도는 2차 고용안전망입니다.', 'labels': {'label': 0.6, 'real-label': 0.5714285714285714, 'binary-label': 0}}\n",
            "{'guid': 'klue-sts-v1_train_00004', 'source': 'airbnb-rtt', 'sentence1': '호스트의 답장이 늦으나, 개선될 것으로 보입니다.', 'sentence2': '호스트 응답이 늦었지만 개선될 것으로 보입니다.', 'labels': {'label': 4.7, 'real-label': 4.714285714285714, 'binary-label': 1}}\n",
            "{'guid': 'klue-sts-v1_train_00005', 'source': 'policy-sampled', 'sentence1': '정부가 새로운 일자리를 직접 창출하는 노력도 배가하겠습니다.', 'sentence2': '세계에서 우리만큼 오랜 역사와 문화를 공유하는 가까운 이웃이 없습니다.', 'labels': {'label': 0.0, 'real-label': 0.0, 'binary-label': 0}}\n",
            "{'guid': 'klue-sts-v1_train_00006', 'source': 'airbnb-rtt', 'sentence1': '지하철을 타도 30분안에는 이동이 가능합니다!', 'sentence2': '지하철을 탄다고 해도, 30분이면 그곳에 도착할 수 있어요!', 'labels': {'label': 4.0, 'real-label': 4.0, 'binary-label': 1}}\n",
            "{'guid': 'klue-sts-v1_train_00007', 'source': 'policy-sampled', 'sentence1': '사례집은 국립환경과학원 누리집(ecolibrary.me.go.kr)에서 12일부터 볼 수 있다.', 'sentence2': '주말을 제외한 평일 오후 12시 30분부터 문예회관 공식 페이스북과 유튜브에서는 지역 예술인들이 중심이 된 서양음악, 국악, 댄스 등의 공연을 실시간으로 감상할 수 있다.', 'labels': {'label': 0.0, 'real-label': 0.0, 'binary-label': 0}}\n",
            "{'guid': 'klue-sts-v1_train_00008', 'source': 'paraKQC-sampled', 'sentence1': '환퐁기 작동 방법 좀 설명해줘', 'sentence2': '조명등 낮에 켜놓으면 큰일나', 'labels': {'label': 0.1, 'real-label': 0.1428571428571428, 'binary-label': 0}}\n",
            "{'guid': 'klue-sts-v1_train_00009', 'source': 'airbnb-rtt', 'sentence1': '새로운 친구들을 만나고 싶을때 아주 추천합니다.', 'sentence2': '새로운 친구들을 만나고 싶을 때 추천합니다.', 'labels': {'label': 4.4, 'real-label': 4.428571428571429, 'binary-label': 1}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 load test"
      ],
      "metadata": {
        "id": "tJHMk6uvfaYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForNextSentencePrediction.from_pretrained(\"klue/roberta-large\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"klue/roberta-large\")"
      ],
      "metadata": {
        "id": "KUavAuCYM0te",
        "outputId": "b8389714-0359-4a3b-c914-f83941f23631",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type roberta to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "Some weights of the model checkpoint at klue/roberta-large were not used when initializing BertForNextSentencePrediction: ['roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.20.attention.self.value.bias', 'roberta.encoder.layer.22.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.encoder.layer.20.output.dense.weight', 'roberta.encoder.layer.8.intermediate.dense.weight', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.21.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.21.intermediate.dense.bias', 'roberta.encoder.layer.22.attention.self.query.bias', 'roberta.encoder.layer.13.attention.output.dense.bias', 'roberta.encoder.layer.19.attention.output.dense.bias', 'roberta.encoder.layer.16.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.13.attention.self.value.bias', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.encoder.layer.23.attention.self.key.bias', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.20.attention.output.LayerNorm.bias', 'roberta.encoder.layer.23.intermediate.dense.weight', 'roberta.encoder.layer.13.intermediate.dense.weight', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.17.attention.self.value.bias', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.13.output.LayerNorm.bias', 'roberta.encoder.layer.22.intermediate.dense.bias', 'lm_head.bias', 'roberta.encoder.layer.8.attention.self.key.weight', 'roberta.encoder.layer.22.attention.self.key.bias', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.19.attention.self.value.weight', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.15.attention.self.query.weight', 'roberta.encoder.layer.19.output.dense.bias', 'roberta.encoder.layer.6.intermediate.dense.weight', 'roberta.encoder.layer.14.intermediate.dense.weight', 'roberta.encoder.layer.18.intermediate.dense.bias', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.21.attention.self.query.weight', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.19.output.LayerNorm.bias', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.12.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.20.attention.self.value.weight', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.0.attention.self.key.weight', 'roberta.encoder.layer.13.attention.self.key.bias', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.13.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.encoder.layer.16.attention.self.value.bias', 'roberta.encoder.layer.15.attention.self.key.weight', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.encoder.layer.19.attention.self.query.bias', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.12.intermediate.dense.bias', 'roberta.encoder.layer.15.attention.output.dense.weight', 'lm_head.decoder.weight', 'roberta.encoder.layer.13.attention.self.query.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.12.attention.output.dense.bias', 'roberta.encoder.layer.19.attention.self.key.bias', 'roberta.encoder.layer.19.attention.self.value.bias', 'roberta.encoder.layer.17.attention.output.dense.weight', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.16.attention.self.query.weight', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.15.attention.self.value.weight', 'roberta.encoder.layer.18.intermediate.dense.weight', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.20.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.12.attention.self.query.bias', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.21.attention.output.dense.bias', 'roberta.encoder.layer.22.attention.output.dense.bias', 'roberta.encoder.layer.13.output.LayerNorm.weight', 'roberta.embeddings.token_type_embeddings.weight', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.23.output.LayerNorm.bias', 'roberta.encoder.layer.16.attention.output.dense.bias', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.12.attention.self.value.bias', 'roberta.encoder.layer.13.attention.self.query.weight', 'roberta.encoder.layer.23.attention.self.key.weight', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.15.output.dense.weight', 'roberta.encoder.layer.17.attention.self.query.weight', 'roberta.encoder.layer.18.attention.output.dense.weight', 'roberta.encoder.layer.17.intermediate.dense.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.8.output.dense.bias', 'roberta.encoder.layer.3.attention.self.key.weight', 'roberta.encoder.layer.23.attention.self.value.bias', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.18.attention.self.key.bias', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.15.attention.output.LayerNorm.weight', 'roberta.encoder.layer.14.attention.output.dense.bias', 'roberta.encoder.layer.17.attention.self.key.bias', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.14.attention.self.key.weight', 'roberta.encoder.layer.15.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.23.intermediate.dense.bias', 'roberta.encoder.layer.15.intermediate.dense.weight', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.16.attention.output.LayerNorm.weight', 'roberta.encoder.layer.17.attention.self.value.weight', 'roberta.encoder.layer.21.intermediate.dense.weight', 'roberta.encoder.layer.17.intermediate.dense.weight', 'roberta.encoder.layer.22.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.17.output.LayerNorm.weight', 'roberta.encoder.layer.18.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.encoder.layer.16.attention.self.key.weight', 'roberta.encoder.layer.17.output.LayerNorm.bias', 'roberta.encoder.layer.17.attention.output.dense.bias', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.16.attention.output.dense.weight', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.encoder.layer.12.attention.self.value.weight', 'roberta.encoder.layer.14.attention.self.value.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.18.attention.output.dense.bias', 'roberta.encoder.layer.12.attention.self.query.weight', 'lm_head.decoder.bias', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.22.attention.self.value.weight', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.22.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.20.intermediate.dense.bias', 'roberta.encoder.layer.13.output.dense.bias', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.15.attention.self.value.bias', 'roberta.encoder.layer.18.output.dense.weight', 'roberta.encoder.layer.20.output.LayerNorm.weight', 'roberta.embeddings.word_embeddings.weight', 'roberta.encoder.layer.14.attention.self.query.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.16.output.dense.weight', 'roberta.encoder.layer.16.intermediate.dense.weight', 'roberta.encoder.layer.22.attention.self.value.bias', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.encoder.layer.12.attention.output.LayerNorm.bias', 'roberta.encoder.layer.12.output.LayerNorm.bias', 'roberta.encoder.layer.13.output.dense.weight', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.15.attention.output.dense.bias', 'roberta.embeddings.LayerNorm.weight', 'roberta.encoder.layer.20.attention.self.key.weight', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.18.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.16.attention.self.query.bias', 'roberta.encoder.layer.19.attention.output.LayerNorm.bias', 'roberta.encoder.layer.18.attention.self.value.weight', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.encoder.layer.18.attention.self.key.weight', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.15.attention.self.key.bias', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.encoder.layer.21.attention.self.value.bias', 'roberta.encoder.layer.22.output.dense.bias', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.15.intermediate.dense.bias', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.16.attention.self.value.weight', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.16.output.dense.bias', 'roberta.encoder.layer.21.attention.self.key.bias', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.16.intermediate.dense.bias', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.23.attention.self.value.weight', 'roberta.encoder.layer.22.intermediate.dense.weight', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.14.attention.self.key.bias', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.13.attention.self.key.weight', 'roberta.encoder.layer.20.output.dense.bias', 'lm_head.dense.weight', 'roberta.embeddings.position_embeddings.weight', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.embeddings.LayerNorm.bias', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.12.attention.self.key.bias', 'roberta.encoder.layer.21.attention.self.query.bias', 'roberta.encoder.layer.21.attention.output.dense.weight', 'roberta.encoder.layer.17.output.dense.weight', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.encoder.layer.21.output.dense.weight', 'roberta.encoder.layer.22.attention.self.key.weight', 'roberta.encoder.layer.13.attention.self.value.weight', 'roberta.encoder.layer.18.attention.self.query.bias', 'roberta.encoder.layer.21.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.output.dense.bias', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.18.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.12.attention.self.key.weight', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.encoder.layer.7.attention.self.key.bias', 'roberta.encoder.layer.0.attention.self.query.weight', 'roberta.embeddings.position_ids', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.encoder.layer.22.attention.output.dense.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.10.attention.self.key.bias', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.2.attention.output.dense.weight', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.9.attention.self.key.weight', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.14.output.dense.bias', 'roberta.encoder.layer.15.output.LayerNorm.weight', 'roberta.encoder.layer.21.output.dense.bias', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.12.attention.output.dense.weight', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.2.attention.self.query.bias', 'roberta.encoder.layer.0.output.dense.weight', 'roberta.encoder.layer.19.output.dense.weight', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.17.attention.output.LayerNorm.bias', 'roberta.encoder.layer.12.output.dense.bias', 'roberta.encoder.layer.16.output.LayerNorm.weight', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.14.output.dense.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.15.output.dense.bias', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.19.attention.self.key.weight', 'roberta.encoder.layer.20.attention.self.query.bias', 'roberta.encoder.layer.18.output.dense.bias', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.intermediate.dense.weight', 'lm_head.layer_norm.weight', 'roberta.encoder.layer.20.output.LayerNorm.bias', 'roberta.encoder.layer.18.attention.self.value.bias', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.17.output.dense.bias', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.15.attention.self.query.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.14.attention.output.dense.weight', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.23.attention.output.LayerNorm.bias', 'roberta.encoder.layer.19.attention.self.query.weight', 'roberta.encoder.layer.17.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.7.attention.self.query.weight', 'roberta.encoder.layer.20.attention.output.dense.bias', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.intermediate.dense.bias', 'roberta.encoder.layer.19.intermediate.dense.weight', 'roberta.encoder.layer.17.attention.self.key.weight', 'roberta.encoder.layer.12.output.dense.weight', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.21.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.20.attention.self.key.bias', 'roberta.encoder.layer.19.attention.output.dense.weight', 'roberta.encoder.layer.23.attention.output.dense.bias', 'roberta.encoder.layer.23.output.dense.bias', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.23.attention.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.encoder.layer.18.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.0.attention.output.dense.bias', 'roberta.encoder.layer.13.intermediate.dense.bias', 'roberta.encoder.layer.14.intermediate.dense.bias', 'lm_head.dense.bias', 'roberta.encoder.layer.23.output.LayerNorm.weight', 'roberta.encoder.layer.22.attention.self.query.weight', 'roberta.encoder.layer.16.output.LayerNorm.bias', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.21.attention.self.value.weight', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.20.intermediate.dense.weight', 'roberta.encoder.layer.23.attention.self.query.bias', 'roberta.encoder.layer.15.output.LayerNorm.bias', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.14.attention.self.query.bias', 'roberta.encoder.layer.14.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.self.query.weight', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.12.intermediate.dense.weight', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.0.attention.output.dense.weight', 'roberta.encoder.layer.23.attention.self.query.weight', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.23.output.dense.weight', 'roberta.encoder.layer.13.attention.output.dense.weight', 'roberta.encoder.layer.14.attention.output.LayerNorm.bias', 'roberta.encoder.layer.20.attention.output.dense.weight', 'roberta.encoder.layer.9.attention.self.query.bias', 'roberta.encoder.layer.21.attention.self.key.weight', 'roberta.encoder.layer.19.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'lm_head.layer_norm.bias', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.14.output.LayerNorm.bias', 'roberta.encoder.layer.17.attention.self.query.bias', 'roberta.encoder.layer.22.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.output.dense.weight', 'roberta.encoder.layer.0.attention.self.query.bias', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.encoder.layer.12.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.0.attention.self.value.weight', 'roberta.encoder.layer.19.attention.output.LayerNorm.weight', 'roberta.encoder.layer.19.intermediate.dense.bias', 'roberta.encoder.layer.18.attention.self.query.weight', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.encoder.layer.23.attention.output.dense.weight', 'roberta.encoder.layer.14.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.self.query.weight', 'roberta.encoder.layer.13.attention.output.LayerNorm.weight', 'roberta.encoder.layer.16.attention.self.key.bias', 'roberta.encoder.layer.14.attention.self.value.weight', 'roberta.encoder.layer.22.output.dense.weight', 'roberta.encoder.layer.21.attention.output.LayerNorm.weight', 'roberta.encoder.layer.20.attention.self.query.weight']\n",
            "- This IS expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForNextSentencePrediction were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['encoder.layer.14.attention.self.key.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.17.attention.self.key.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.21.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.9.output.LayerNorm.weight', 'cls.seq_relationship.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.value.weight', 'pooler.dense.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.23.attention.self.key.weight', 'pooler.dense.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.20.output.dense.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.13.output.dense.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.13.output.LayerNorm.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.14.output.dense.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.22.output.dense.weight', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'embeddings.LayerNorm.bias', 'cls.seq_relationship.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.17.intermediate.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 0과 2의 의미\n",
        "tensorized_input = tokenizer('숙소 위치는 찾기 쉽고 일반적인 한국의 반지하 숙소입니다.',\n",
        " '숙박시설의 위치는 쉽게 찾을 수 있고 한국의 대표적인 반지하 숙박시설입니다.'\n",
        "    )\n",
        "tensorized_input"
      ],
      "metadata": {
        "id": "SHnFdJl2Tmyi",
        "outputId": "1b05d8ee-bf3e-441e-bae8-2f44225581c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [0, 9206, 4318, 2259, 1642, 2015, 1311, 2088, 3935, 31221, 3629, 2079, 10817, 2205, 9206, 12190, 18, 2, 8134, 10171, 2079, 4318, 2259, 1311, 2318, 1642, 2069, 1295, 1513, 2088, 3629, 2079, 3661, 31221, 10817, 2205, 8134, 10171, 12190, 18, 2], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(tokenizer.encode('숙소 위치는 찾기 쉽고 일반적인 한국의 반지하 숙소입니다.',\n",
        " '숙박시설의 위치는 쉽게 찾을 수 있고 한국의 대표적인 반지하 숙박시설입니다.'))"
      ],
      "metadata": {
        "id": "G6RNJaOmWeir",
        "outputId": "7f066e22-d5cf-4fee-b0b1-3c0cd172d637",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[CLS] 숙소 위치는 찾기 쉽고 일반적인 한국의 반지하 숙소입니다. [SEP] 숙박시설의 위치는 쉽게 찾을 수 있고 한국의 대표적인 반지하 숙박시설입니다. [SEP]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(\n",
        "            **tensorized_input\n",
        "        )\n",
        "outputs.logits    # 같을 확률 / 아닐 확률"
      ],
      "metadata": {
        "id": "zKCKnTvMNS8x",
        "outputId": "65270205-5725-4371-fb79-a8fdfa2ff01f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1542, -0.1047]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nn.functional.softmax(outputs.logits)"
      ],
      "metadata": {
        "id": "2WymleIWT3eQ",
        "outputId": "3b5cedaa-5848-457b-d608-4c7359825be6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4876, 0.5124]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensorized_input = tokenizer(\n",
        "        '숙소 위치는 찾기 쉽고 일반적인 한국의 반지하 숙소입니다.',\n",
        "        '숙소 위치는 찾기 쉽고 일반적인 한국의 반지하 숙소입니다.',\n",
        "        add_special_tokens=True,\n",
        "        padding=\"longest\",  # 배치내 가장 긴 문장을 기준으로 부족한 문장은 [PAD] 토큰을 추가\n",
        "        truncation=True, # max_length를 넘는 문장은 이 후 토큰을 제거함\n",
        "        max_length=512,\n",
        "        return_tensors='pt' # 토크나이즈된 결과 값을 텐서 형태로 반환\n",
        "    )\n",
        "outputs = model(\n",
        "            **tensorized_input\n",
        "        )\n",
        "outputs"
      ],
      "metadata": {
        "id": "oLWgTf8XNXNY",
        "outputId": "d01098b7-1355-4bf2-d48b-bbed87547bd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NextSentencePredictorOutput([('logits',\n",
              "                              tensor([[-0.1558, -0.1170]], grad_fn=<AddmmBackward0>))])"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensorized_input = tokenizer(\n",
        "'새로운 친구들을 만나고 싶을 때 추천합니다.', \n",
        "'새로운 친구들을 만나고 싶을 때 추천합니다.',\n",
        "        add_special_tokens=True,\n",
        "        padding=\"longest\",  # 배치내 가장 긴 문장을 기준으로 부족한 문장은 [PAD] 토큰을 추가\n",
        "        truncation=True, # max_length를 넘는 문장은 이 후 토큰을 제거함\n",
        "        max_length=512,\n",
        "        return_tensors='pt' # 토크나이즈된 결과 값을 텐서 형태로 반환\n",
        "    )\n",
        "outputs = model(\n",
        "            **tensorized_input, labels=torch.tensor([0])\n",
        "        )\n",
        "outputs"
      ],
      "metadata": {
        "id": "feQVZk8BNouo",
        "outputId": "f33932ba-09b2-4271-f7d3-c751099f45c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NextSentencePredictorOutput([('loss',\n",
              "                              tensor(0.7599, grad_fn=<NllLossBackward0>)),\n",
              "                             ('logits',\n",
              "                              tensor([[-0.2058, -0.0764]], grad_fn=<AddmmBackward0>))])"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Tokenizing -> dataLoader"
      ],
      "metadata": {
        "id": "kMX55thM_Owd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler"
      ],
      "metadata": {
        "id": "xpST6GczRO6N"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    \"\"\"\n",
        "    문서 리스트를 받아 skip-gram 방식의 (target_word, context_word) 데이터 셋을 생성\n",
        "    \"\"\"\n",
        "    def __init__(self, dataset):\n",
        "        self.sentence1, self.sentence2, self.labels = self.make_dataset(dataset)\n",
        "    \n",
        "    def make_dataset(self, dataset):\n",
        "        \"\"\"\n",
        "        self.label : dataset의 label의 list\n",
        "        self.input : sentence1, sentence2를 tokenizer한 값을 이어 붙임 \n",
        "        \"\"\"\n",
        "        sentence1, sentence2 = [], []\n",
        "        rlabels = []  # real-label\n",
        "        # blabel = [] # binary-label\n",
        "\n",
        "        for data in dataset :\n",
        "          rlabels.append(data['labels']['real-label'])\n",
        "          # blabel.append(data['labels']['binary-label'])\n",
        "          sentence1.append(data['sentence1'])\n",
        "          sentence2.append(data['sentence2'])\n",
        "        return sentence1, sentence2, rlabels\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.sentence1[idx], self.sentence2[idx], self.labels[idx]"
      ],
      "metadata": {
        "id": "P7VYohZZeCbW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_collate_fn(batch):\n",
        "    \"\"\"\n",
        "    - batch: list of tuples (input1_data(string), input2_data(string), target_data(int))\n",
        "    \n",
        "    한 배치 내 문장들을 tokenizing 한 후 텐서로 변환함. \n",
        "    이때, dynamic padding (즉, 같은 배치 내 토큰의 개수가 동일할 수 있도록, 부족한 문장에 [PAD] 토큰을 추가하는 작업)을 적용\n",
        "    \n",
        "    한 배치 내 레이블(target)은 텐서화 함.\n",
        "    \n",
        "    (input, target) 튜플 형태를 반환.\n",
        "    \"\"\"\n",
        "    input1_list, input2_list, target_list = [], [], []\n",
        "    \n",
        "    for _input1, _input2, _target in batch:\n",
        "        input1_list.append(_input1)\n",
        "        input2_list.append(_input2)\n",
        "        target_list.append(_target)\n",
        "    \n",
        "    tensorized_input = tokenizer(\n",
        "        input1_list, input2_list,\n",
        "        add_special_tokens=True,\n",
        "        padding=\"longest\",  # 배치내 가장 긴 문장을 기준으로 부족한 문장은 [PAD] 토큰을 추가\n",
        "        truncation=True, # max_length를 넘는 문장은 이 후 토큰을 제거함\n",
        "        max_length=512,\n",
        "        return_tensors='pt' # 토크나이즈된 결과 값을 텐서 형태로 반환\n",
        "    )\n",
        "    \n",
        "    tensorized_label = torch.tensor(target_list)\n",
        "    \n",
        "    return tensorized_input, tensorized_label"
      ],
      "metadata": {
        "id": "FBrzwcq1EMC6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"snunlp/KR-Medium\")"
      ],
      "metadata": {
        "id": "3VNezYanqjQP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(dataset['train'])\n",
        "valid_dataset = CustomDataset(dataset['validation'])\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size =32,\n",
        "    sampler = RandomSampler(train_dataset),\n",
        "    collate_fn = custom_collate_fn\n",
        ")\n",
        "valid_dataloader = DataLoader(\n",
        "    valid_dataset,\n",
        "    batch_size =32,\n",
        "    sampler = SequentialSampler(valid_dataset),\n",
        "    collate_fn = custom_collate_fn\n",
        ")"
      ],
      "metadata": {
        "id": "J2M5WpvbGO5O"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizing 잘 되었는지 확인\n",
        "for input_batch, target_batch in train_dataloader:\n",
        "    print(f\"Batch input shape: {input_batch['input_ids'].shape}\")\n",
        "    print(input_batch['input_ids'])\n",
        "    print(f\"Batch target shape: {target_batch.shape}\")\n",
        "    break"
      ],
      "metadata": {
        "id": "QWNzv1VeGU1M",
        "outputId": "ad238123-2868-4f0f-fbf0-68de63793ab1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch input shape: torch.Size([32, 100])\n",
            "tensor([[    2,  3576,  9163,  ...,     0,     0,     0],\n",
            "        [    2,  8722,  2401,  ...,     0,     0,     0],\n",
            "        [    2,  9536,  5143,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [    2, 12653,  3597,  ...,     0,     0,     0],\n",
            "        [    2,  2017,  5034,  ...,     0,     0,     0],\n",
            "        [    2, 19024,  2242,  ...,     0,     0,     0]])\n",
            "Batch target shape: torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# model"
      ],
      "metadata": {
        "id": "wo6N6cZgNDRj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 클래스\n",
        "class CustomSTS(nn.Module):\n",
        "    def __init__(self, hidden_size: int, config=None):\n",
        "        super(CustomSTS, self).__init__()\n",
        "        self.config = config\n",
        "        self.model = BertForNextSentencePrediction.from_pretrained(self.config.bert_model)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, labels=None):\n",
        "        \"\"\"\n",
        "        outputs(NextSentencePredictorOutput) : logtis, loss(next_sentence_label이 주어질 때 return)\n",
        "                hidden_states(optional), attentions(optional) 을 가지고 있다.\n",
        "        loss는 주어진 label이 0~5 사이의 값으로 scale 되어있기 때문에 직접 구해야한다!\n",
        "        \"\"\"\n",
        "        outputs = self.model(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "        )\n",
        "        # logits's shape : (batch_size, 2)\n",
        "        logits = self.model(input_ids, token_type_ids=token_type_ids).logits\n",
        "        probs = self.softmax(logits)\n",
        "        probs = probs[:, 0] * 5    # 0~5 사이의 값으로 정답(T)일 확률 뽑아내기\n",
        "        return probs    # 정답(T)일 확률"
      ],
      "metadata": {
        "id": "rvWujlFzYLR6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# train"
      ],
      "metadata": {
        "id": "964Xf_8dXx-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import AdamW\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "from transformers import get_linear_schedule_with_warmup, get_constant_schedule"
      ],
      "metadata": {
        "id": "RvFl_BeDTnsV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model, optimizer, scheduler 초기화"
      ],
      "metadata": {
        "id": "f6UwWz0Uo5xa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Config(BertConfig):\n",
        "  def __init__(self) :\n",
        "    super().__init__()\n",
        "    self.task= 'sts'\n",
        "    self.bert_model = 'snunlp/KR-Medium'    # kr-bert\n",
        "    self.max_len= 512\n",
        "    self.dropout_rate= 0.1"
      ],
      "metadata": {
        "id": "Le8gzToif-gZ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initializer(train_dataloader, epochs=2):\n",
        "    \"\"\"\n",
        "    모델, 옵티마이저, 스케쥴러 초기화\n",
        "    \"\"\"\n",
        "    config = Config()\n",
        "    model = CustomSTS(hidden_size=768, config=config)\n",
        "\n",
        "    optimizer = AdamW(\n",
        "        model.parameters(), # update 대상 파라미터를 입력\n",
        "        lr=2e-5,\n",
        "        eps=1e-8\n",
        "    )\n",
        "    \n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "    print(f\"Total train steps with {epochs} epochs: {total_steps}\")\n",
        "\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer, \n",
        "        num_warmup_steps = 0, # 여기서는 warmup을 사용하지 않는다.\n",
        "        num_training_steps = total_steps\n",
        "    )\n",
        "\n",
        "    return model, optimizer, scheduler"
      ],
      "metadata": {
        "id": "Nm9fgX3SpAHs"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### checkpoint"
      ],
      "metadata": {
        "id": "tq-7ThFjovDX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_checkpoint(path, model, optimizer, scheduler, epoch, loss):\n",
        "    file_name = f'{path}/model.ckpt.{epoch}'\n",
        "    \n",
        "    torch.save(\n",
        "        {\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict(),\n",
        "            'loss' : loss\n",
        "        }, \n",
        "        file_name\n",
        "    )\n",
        "    \n",
        "    print(f\"Saving epoch {epoch} checkpoint at {file_name}\")"
      ],
      "metadata": {
        "id": "CQ9Gdhuuoug4"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### train code"
      ],
      "metadata": {
        "id": "txIbdOd3oyR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_dataloader, valid_dataloader=None, epochs=1):\n",
        "        loss_fct = nn.MSELoss()\n",
        "\n",
        "\n",
        "        no_decay = ['bias', 'LayerNorm.weight']\n",
        "        optimizer_grouped_parameters = [\n",
        "            {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "            {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "        ]\n",
        "        optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5, eps=1e-8)  # lr = learning rate\n",
        "        \n",
        "        before_loss = 0\n",
        "        \n",
        "        for epoch in range(epochs) :\n",
        "\n",
        "            print(f\"*****Epoch {epoch} Train Start*****\")\n",
        "            # 배치 단위 평균 loss와 총 평균 loss 계산하기위해 변수 생성\n",
        "            total_loss, batch_loss, batch_count = 0,0,0\n",
        "            \n",
        "            # model을 train 모드로 설정 & device 할당\n",
        "            model.train()\n",
        "            model.to(device)\n",
        "            \n",
        "            # data iterator를 돌면서 하나씩 학습\n",
        "            for step, batch in enumerate(train_dataloader):\n",
        "                batch_count+=1\n",
        "                \n",
        "                # tensor 연산 전, 각 tensor에 device 할당\n",
        "                batch = tuple(item.to(device) for item in batch)\n",
        "                \n",
        "                batch_input, batch_label = batch\n",
        "                \n",
        "                # batch마다 모델이 갖고 있는 기존 gradient를 초기화/??\n",
        "                model.zero_grad()\n",
        "                \n",
        "                # forward\n",
        "                probs = model(**batch_input)\n",
        "                \n",
        "                # loss\n",
        "                loss = loss_fct(probs, batch_label)    # \n",
        "                batch_loss += loss\n",
        "                total_loss += loss\n",
        "                \n",
        "                # backward -> 파라미터의 미분(gradient)를 자동으로 계산\n",
        "                loss.backward()\n",
        "                \n",
        "                # gradient clipping 적용 \n",
        "                clip_grad_norm_(model.parameters(), 1.0)\n",
        "                \n",
        "                # optimizer & scheduler 업데이트\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "\n",
        "\n",
        "                # 배치 100개씩 처리할 때마다 평균 loss와 lr를 출력\n",
        "                if (step % 100 == 0 and step != 0):\n",
        "                    learning_rate = optimizer.param_groups[0]['lr']\n",
        "                    print(f\"Epoch: {epoch}, Step : {step}, LR : {learning_rate}, Avg Loss : {batch_loss / batch_count:.4f}\")\n",
        "\n",
        "                    # 변수 초기화 \n",
        "                    batch_loss, batch_count = 0,0\n",
        "\n",
        "\n",
        "            print(f\"Epoch {epoch} Total Mean Loss : {total_loss/(step+1):.4f}\")\n",
        "            print(f\"*****Epoch {epoch} Train Finish*****\\n\")\n",
        "            \n",
        "            if valid_dataloader is not None:\n",
        "                print(f\"*****Epoch {epoch} Valid Start*****\")\n",
        "                valid_loss, valid_acc = validate(model, valid_dataloader)\n",
        "                print(f\"Epoch {epoch} Valid Loss : {valid_loss:.4f} Valid Acc : {valid_acc:.2f}\")\n",
        "                print(f\"*****Epoch {epoch} Valid Finish*****\\n\")\n",
        "\n",
        "            if before_loss > valid_loss :\n",
        "                before_loss = valid_loss\n",
        "                save_checkpoint(\".\", model, optimizer, scheduler, epoch, total_loss/(step+1))\n",
        "\n",
        "        print(\"Train Finished\")\n",
        "\n",
        "            # validation!!\n"
      ],
      "metadata": {
        "id": "HluWdArhYFIC"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### validation code"
      ],
      "metadata": {
        "id": "w2AMocOkozvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(model, valid_dataloader):\n",
        "    loss_fct = nn.MSELoss()\n",
        "    # 모델을 evaluate 모드로 설정 & device 할당\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    \n",
        "    total_loss, total_acc= 0,0\n",
        "        \n",
        "    for step, batch in enumerate(valid_dataloader):\n",
        "        \n",
        "        # tensor 연산 전, 각 tensor에 device 할당\n",
        "        batch = tuple(item.to(device) for item in batch)\n",
        "            \n",
        "        batch_input, batch_label = batch\n",
        "            \n",
        "        # gradient 계산하지 않음\n",
        "        with torch.no_grad():\n",
        "            probs = model(**batch_input)\n",
        "            \n",
        "        # loss\n",
        "        loss = loss_fct(probs, batch_label)\n",
        "        total_loss += loss.item()\n",
        "        \n",
        "        # accuracy\n",
        "        acc = 0\n",
        "        for p, b in zip(probs, batch_label) :\n",
        "          if (p > 3 and b > 3) or (p < 3 and b < 3 ) :\n",
        "            acc += 1\n",
        "        \n",
        "        acc = acc / len(probs)\n",
        "        \n",
        "        total_acc+=acc\n",
        "    \n",
        "    total_loss = total_loss/(step+1)\n",
        "    total_acc = total_acc/(step+1)*100\n",
        "\n",
        "    return total_loss, total_acc"
      ],
      "metadata": {
        "id": "D9DpetR6oTdb"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train"
      ],
      "metadata": {
        "id": "Ies_fsGgo22Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=4\n",
        "model, optimizer, scheduler = initializer(train_dataloader, epochs)\n",
        "train(model, train_dataloader, valid_dataloader, epochs)"
      ],
      "metadata": {
        "id": "I4ybF3tWrNf1",
        "outputId": "54aee150-51f0-4007-b794-f3ced08fdc94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at snunlp/KR-Medium were not used when initializing BertForNextSentencePrediction: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total train steps with 4 epochs: 1460\n",
            "*****Epoch 0 Train Start*****\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Step : 100, LR : 2e-05, Avg Loss : 0.8805\n",
            "Epoch: 0, Step : 200, LR : 2e-05, Avg Loss : 0.3660\n",
            "Epoch: 0, Step : 300, LR : 2e-05, Avg Loss : 0.2870\n",
            "Epoch 0 Total Mean Loss : 0.4696\n",
            "*****Epoch 0 Train Finish*****\n",
            "\n",
            "*****Epoch 0 Valid Start*****\n",
            "Epoch 0 Valid Loss : 1.0223 Valid Acc : 69.43\n",
            "*****Epoch 0 Valid Finish*****\n",
            "\n",
            "*****Epoch 1 Train Start*****\n",
            "Epoch: 1, Step : 100, LR : 2e-05, Avg Loss : 0.1799\n",
            "Epoch: 1, Step : 200, LR : 2e-05, Avg Loss : 0.1856\n",
            "Epoch: 1, Step : 300, LR : 2e-05, Avg Loss : 0.1836\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "flYW_3hHrM2s"
      }
    }
  ]
}